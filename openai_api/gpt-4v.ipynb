{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4b6a552-b7f0-433d-9a70-61c4fcc52d5d",
   "metadata": {},
   "source": [
    "# 快速入门 GPT-4 Vison\n",
    "\n",
    "从历史上看，语言模型系统仅接受**文本**作为输入。但是单一的输入形式，限制了大模型的应用落地范围。\n",
    "\n",
    "随着技术发展，OpenAI 开发的 GPT-4 Turbo with Vision（简称 GPT-4V）允许模型接收**图像**作为输入，并回答关于它们的问题。\n",
    "\n",
    "📢注意，目前在 Assistants API 中使用 GPT-4 时还不支持图像输入。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a701c56-0a2a-4dea-b458-234150b84ff2",
   "metadata": {},
   "source": [
    "## 使用 GPT-4V 识别线上图像（URL）\n",
    "\n",
    "![image_sample](https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf8689b2-94f2-4a35-a332-9ffed0a56aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='这幅图展示了一个拥有非常美丽自然景观的地方。画面主要是一条木板路，引领视线穿越广阔的绿色草地，直到远处的树木和天际。图中的天空呈现出丰富的蓝色和少量白云，增添了开阔和宁静的氛围。光线柔和，加上木板路和蓝天的自然对比，构成了一幅引人入胜的自然风光画面。这样的场景可能位于一个公园或自然保护区，提供了一个适合散步和放松的环境。整体来看，这是一幅充满和谐与宁静感的自然景观照片。', role='assistant', function_call=None, tool_calls=None, refusal=None))\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "     api_key='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'\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\"type\": \"text\", \"text\": \"介绍下这幅图?\"},\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\",\n",
    "          },\n",
    "        },\n",
    "      ],\n",
    "    }\n",
    "  ],\n",
    "  max_tokens=300,\n",
    ")\n",
    "\n",
    "print(response.choices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bcc9026-7485-428f-8269-ea9ae41405cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'这幅图展示了一个拥有非常美丽自然景观的地方。画面主要是一条木板路，引领视线穿越广阔的绿色草地，直到远处的树木和天际。图中的天空呈现出丰富的蓝色和少量白云，增添了开阔和宁静的氛围。光线柔和，加上木板路和蓝天的自然对比，构成了一幅引人入胜的自然风光画面。这样的场景可能位于一个公园或自然保护区，提供了一个适合散步和放松的环境。整体来看，这是一幅充满和谐与宁静感的自然景观照片。'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb50a14-fa14-4c63-9f81-b98b0f65d9d9",
   "metadata": {},
   "source": [
    "### 封装成一个函数 query_image_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1ca5428-c7e1-4d7e-91f1-d4a05e95ac51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_image_description(url, prompt=\"介绍下这幅图?\"):\n",
    "    client = OpenAI(\n",
    "         api_key='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'\n",
    "    )  # 初始化 OpenAI 客户端\n",
    "    \n",
    "    # 发送请求给 OpenAI 的聊天模型\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4-turbo\",  # 指定使用的模型\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": prompt},\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\"url\": url}},\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=300,\n",
    "    )\n",
    "    \n",
    "    # 返回模型的响应\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d0aceb-7cc5-4da1-b6db-e47716ba145a",
   "metadata": {},
   "source": [
    "### 调用函数测试\n",
    "\n",
    "![meme_0](https://p6.itc.cn/q_70/images03/20200602/0c267a0d3d814c9783659eb956969ba1.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "454abb5c-49d3-42e6-867e-f44e25af5e0e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-KeqW6***************************************WnHP. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m image_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://p6.itc.cn/q_70/images03/20200602/0c267a0d3d814c9783659eb956969ba1.jpeg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m content \u001b[38;5;241m=\u001b[39m query_image_description(image_url)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(content)\n",
      "Cell \u001b[0;32mIn[5], line 7\u001b[0m, in \u001b[0;36mquery_image_description\u001b[0;34m(url, prompt)\u001b[0m\n\u001b[1;32m      2\u001b[0m client \u001b[38;5;241m=\u001b[39m OpenAI(\n\u001b[1;32m      3\u001b[0m      api_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msk-KeqW6o1q4cLshVDejBGFT3BlbkFJrArzlKyfkNpVg5YTWnHP\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m )  \u001b[38;5;66;03m# 初始化 OpenAI 客户端\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# 发送请求给 OpenAI 的聊天模型\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m      8\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4-turbo\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# 指定使用的模型\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     messages\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m     10\u001b[0m         {\n\u001b[1;32m     11\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m     13\u001b[0m                 {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt},\n\u001b[1;32m     14\u001b[0m                 {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m: url}},\n\u001b[1;32m     15\u001b[0m             ],\n\u001b[1;32m     16\u001b[0m         }\n\u001b[1;32m     17\u001b[0m     ],\n\u001b[1;32m     18\u001b[0m     max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m,\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# 返回模型的响应\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/openai/_utils/_utils.py:275\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/openai/resources/chat/completions.py:667\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    665\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    666\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 667\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[1;32m    668\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    669\u001b[0m         body\u001b[38;5;241m=\u001b[39mmaybe_transform(\n\u001b[1;32m    670\u001b[0m             {\n\u001b[1;32m    671\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[1;32m    672\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[1;32m    673\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[1;32m    674\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m: function_call,\n\u001b[1;32m    675\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m: functions,\n\u001b[1;32m    676\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n\u001b[1;32m    677\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs,\n\u001b[1;32m    678\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[1;32m    679\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n\u001b[1;32m    680\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n\u001b[1;32m    681\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[1;32m    682\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[1;32m    683\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop,\n\u001b[1;32m    684\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[1;32m    685\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[1;32m    686\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n\u001b[1;32m    687\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[1;32m    688\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_logprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_logprobs,\n\u001b[1;32m    689\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[1;32m    690\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[1;32m    691\u001b[0m             },\n\u001b[1;32m    692\u001b[0m             completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParams,\n\u001b[1;32m    693\u001b[0m         ),\n\u001b[1;32m    694\u001b[0m         options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[1;32m    695\u001b[0m             extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[1;32m    696\u001b[0m         ),\n\u001b[1;32m    697\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mChatCompletion,\n\u001b[1;32m    698\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    699\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mStream[ChatCompletionChunk],\n\u001b[1;32m    700\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/openai/_base_client.py:1208\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1195\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1196\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1203\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1204\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1205\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1206\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1207\u001b[0m     )\n\u001b[0;32m-> 1208\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/openai/_base_client.py:897\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    889\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    890\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    895\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    896\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 897\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[1;32m    898\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m    899\u001b[0m         options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m    900\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m    901\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m    902\u001b[0m         remaining_retries\u001b[38;5;241m=\u001b[39mremaining_retries,\n\u001b[1;32m    903\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/openai/_base_client.py:988\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    985\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m    987\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 988\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    990\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m    991\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m    992\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    995\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m    996\u001b[0m )\n",
      "\u001b[0;31mAuthenticationError\u001b[0m: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-KeqW6***************************************WnHP. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}"
     ]
    }
   ],
   "source": [
    "image_url = \"https://p6.itc.cn/q_70/images03/20200602/0c267a0d3d814c9783659eb956969ba1.jpeg\"\n",
    "content = query_image_description(image_url)\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ae05bd-872c-4638-8259-df4f420aaa1d",
   "metadata": {},
   "source": [
    "### 使用 GPT-4V 识别本地图像文件（Base64编码）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e83da68-d387-46da-8236-78fc607d1fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import base64\n",
    "import requests\n",
    "import json\n",
    "\n",
    "client = OpenAI(api_key='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')  # 初始化 OpenAI 客户端\n",
    "\n",
    "def query_base64_image_description(image_path, prompt=\"解释下图里的内容？\", max_tokens=1000):\n",
    "\n",
    "    # 实现 Base64 编码\n",
    "    def encode_image(path):\n",
    "        with open(path, \"rb\") as image_file:\n",
    "            return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "    # 获取图像的 Base64 编码字符串\n",
    "    base64_image = encode_image(image_path)\n",
    "\n",
    "    # 构造请求的 HTTP Header\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {client.api_key}\"\n",
    "    }\n",
    "\n",
    "    # 构造请求的负载\n",
    "    payload = {\n",
    "        \"model\": \"gpt-4-turbo\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": prompt},\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}}\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"max_tokens\": max_tokens\n",
    "    }\n",
    "\n",
    "    # 发送 HTTP 请求\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "\n",
    "    # 检查响应并提取所需的 content 字段\n",
    "    if response.status_code == 200:\n",
    "        response_data = response.json()\n",
    "        content = response_data['choices'][0]['message']['content']\n",
    "        return content\n",
    "    else:\n",
    "        return f\"Error: {response.status_code}, {response.text}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dd0f99-8086-473f-80a4-497e6dd07c17",
   "metadata": {},
   "source": [
    "#### 使用 Assistants API生成的 GDP 40年对比曲线图\n",
    "\n",
    "![gdp_data](./images/gdp_1980_2020.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c0e9063-e8d9-4bc1-ae60-ad0aa5bee32b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 401, {\n",
      "    \"error\": {\n",
      "        \"message\": \"Incorrect API key provided: sk-KeqW6***************************************WnHP. You can find your API key at https://platform.openai.com/account/api-keys.\",\n",
      "        \"type\": \"invalid_request_error\",\n",
      "        \"param\": null,\n",
      "        \"code\": \"invalid_api_key\"\n",
      "    }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "content = query_base64_image_description(\"./images/gdp_1980_2020.jpg\")\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d18b227-32a6-4450-86bd-c99ad5c533b9",
   "metadata": {},
   "source": [
    "#### 使用 GPT-4V 识别手写体笔记\n",
    "\n",
    "![](./images/handwriting_0.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4193fa11-5edd-404c-9472-0cb8cc6799fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 401, {\n",
      "    \"error\": {\n",
      "        \"message\": \"Incorrect API key provided: sk-KeqW6***************************************WnHP. You can find your API key at https://platform.openai.com/account/api-keys.\",\n",
      "        \"type\": \"invalid_request_error\",\n",
      "        \"param\": null,\n",
      "        \"code\": \"invalid_api_key\"\n",
      "    }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "content = query_base64_image_description(\"./images/handwriting_0.jpg\")\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca046601-018c-455c-ace2-41392cbda456",
   "metadata": {},
   "source": [
    "#### 在 Jupyter 标准输出中渲染 Markdown 格式内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "516ee35b-1337-4b22-aea2-ee0adb706098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "这张图片显示的是一本笔记本上手写的文字，内容主要涉及到自然语言处理（NLP）中的训练技术，如Prompt Tuning和LoRA技术。\n",
       "\n",
       "1. **Prompt Tuning（简要模型调整）**： 提到了使用Prompt Tuning来调整一个小型的Transformer模型。此处解释了输入X（由个别输入X1, X2, ..., Xn组成）。每个输入首先通过一个Embedding过程转换，然后通过Token变换。输出Y是通过矩阵W与转换后的输入X'之间的乘法得出。\n",
       "\n",
       "2. **Prefix Tuning：** 这部分说明了Prefix Tuning的过程，其中添加了前缀权重W_p到原始权重W_j中，得到新的权重W'用于生成输出Y。\n",
       "\n",
       "3. **LoRA调整技术**： 这部分涉及Linear Re-parameterization（线性重新参数化），通过调整矩阵ΔW（通过两个矩阵A和B的乘积表示）来修改权重W。这是一种节省参数调整的方法，使原有模型的W变为W+ΔW，这里也涉及到了一些矩阵运算和优化策略。\n",
       "\n",
       "其中还提到了两个案例分析的存储需求：“LLAMA”需要65GB，而经过LoRA调整的“QLLoRA”仅需要48GB。\n",
       "\n",
       "这些笔记对于理解NLP中一些先进的模型调整技术十分有用，尤其对于需要在资源受限的环境下部署NLP模型的研究人员或实践者。"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "# 使用 display 和 Markdown 函数显示 Markdown 内容\n",
    "display(Markdown(content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72ebbe3-87cc-4867-9cf0-62e5ed684482",
   "metadata": {},
   "source": [
    "![](./images/handwriting_1.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c046958-aa7a-4066-88fa-4134869d9226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "这张图片展示的是一本笔记本的两页，内容涉及深度学习、特别是关于自然语言处理（NLP）的各种技术和方法。主要讨论了Transformer模型及其改进方法和训练技术。\n",
       "\n",
       "左侧页面的上部标注有“自然语言处理”、“基础”和“评价”，可能是对内容的分类。提到了Transformer模型，并列举了不同的测试标准和指标，如PeFT (“Prompt-based Fine-Tuning”) 和模型性能对比（“Benchmark”）。此外，还提到了不同的方法，如Prompt Tuning和Adapter。具体包括：  \n",
       "- Adapter: 一个2019年Google的研究\n",
       "- Prefix: 代表2021年Stanford的工作\n",
       "- Prompt: 同样是2021年Google的研究\n",
       "- P-Tuning V1和V2：2021年的两种方法\n",
       "- Soft prompts：2021年的研究，提示模板基于模板\n",
       "\n",
       "右侧页面讨论了多模态指令式微调（multi-modality instruction FT）、Llama (3B)、LoRA、PETC（2022年的新技术）等。还有部分文字描述了如何使用prefix-tuning和Adapter方法来细化在大型语言模型（LLMs）中的处理。\n",
       "\n",
       "页面提到了几种语言模型，如：\n",
       "- Llama \n",
       "- BLOOM\n",
       "- ChatGLM \n",
       "- Alpaca\n",
       "\n",
       "这些内容表明这本笔记本的主人正在研究或学习NLP领域的最新技术和方法，特别是如何通过各种微调技术提升已有的大型语言模型的性能。"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "content = query_base64_image_description(\"./images/handwriting_1.jpg\")\n",
    "display(Markdown(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156a0f17-cca8-4f01-9ce5-53384b5ffda4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bd772f-9492-4f6c-b05a-666b772ca3c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afdeacb-aac1-4692-be2b-fb7957ba5e8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79a8d459-d98e-4215-9fbf-38ad37080475",
   "metadata": {},
   "source": [
    "## Homework: \n",
    "\n",
    "\n",
    "### #1\n",
    "\n",
    "使用 GPT-4V 识别带有手写体文字的本地图像文件，分享结果。\n",
    "\n",
    "### #2\n",
    "\n",
    "整合 `query_base64_image_description` 函数和 Markdown 格式渲染方法，使得输出结果更易阅读。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0909bf27-9c4a-498c-9fae-0f442062b9a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
